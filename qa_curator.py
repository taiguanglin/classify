#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½›å­¸å•ç­”ç²¾é¸å™¨ - å°ˆé–€ç”¨æ–¼è©•é¸é«˜è³ªé‡çš„ä½›å­¸å•ç­”
æ”¯æŒå…©ç¨®è©•åˆ†æ¨¡å¼ï¼šæŒ‡å®šè¡Œè™Ÿæ¨¡å¼å’Œéæ¿¾çµæœæ¨¡å¼
"""

import configparser
import pandas as pd
import openpyxl
from openpyxl import load_workbook
from openai import OpenAI
import re
import time
import logging
from datetime import datetime
import os
import json
import argparse
from typing import Dict, List, Tuple, Optional, Union, Any

# å°å…¥ç·©å­˜ç³»çµ±
try:
    from filter_cache import FilterCache
    FILTER_CACHE_AVAILABLE = True
except ImportError:
    FILTER_CACHE_AVAILABLE = False
    logger = logging.getLogger("qa_curator")
    if logger:
        logger.warning("ç·©å­˜ç³»çµ±ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨å‚³çµ±æƒææ¨¡å¼")

# è¨­ç½®æ—¥èªŒå‡½æ•¸
def setup_logging():
    """è¨­ç½®æ—¥èªŒé…ç½®"""
    # ç¢ºä¿æ—¥èªŒæ–‡ä»¶å­˜åœ¨
    log_file = "qa_curation.log"
    if not os.path.exists(log_file):
        with open(log_file, "w") as f:
            f.write(f"# ä½›å­¸å•ç­”ç²¾é¸å™¨æ—¥èªŒæ–‡ä»¶ - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n")
    
    # å‰µå»ºè‡ªå®šç¾©logger
    logger = logging.getLogger("qa_curator")
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤ç¾æœ‰handlers
    if logger.handlers:
        logger.handlers.clear()
    
    # å‰µå»ºæ–‡ä»¶handler
    file_handler = logging.FileHandler(log_file, mode="a", encoding="utf-8")
    file_handler.setLevel(logging.INFO)
    
    # å‰µå»ºæ§åˆ¶å°handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # è¨­ç½®æ ¼å¼
    formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # æ·»åŠ handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    logger.info(f"æ—¥èªŒç³»çµ±åˆå§‹åŒ–å®Œæˆ - æ—¥èªŒæ–‡ä»¶: {log_file}")
    
    return logger


# åˆå§‹åŒ–æ—¥èªŒç³»çµ±
logger = setup_logging()

class BuddhistQACurator:
    """ä½›å­¸å•ç­”ç²¾é¸å™¨ - å°ˆé–€ç”¨æ–¼è©•é¸é«˜è³ªé‡çš„ä½›å­¸å•ç­”"""
    
    def __init__(self, config_file: str = 'config.ini', api_key: str = None, api_type: str = None, chatmock_url: str = None):
        """åˆå§‹åŒ–ç²¾é¸å™¨"""
        self.config = configparser.ConfigParser()
        self.config.read(config_file, encoding='utf-8')
        
        # ä¿å­˜å‚æ•°
        self.api_key = api_key
        self.api_type = api_type
        self.chatmock_url = chatmock_url
        
        # åˆå§‹åŒ–OpenAI
        self.setup_openai()
        
        # è¼‰å…¥promptæ¨¡æ¿
        self.prompt_template = self.load_prompt_template()
        
        # åˆå§‹åŒ–ç·©å­˜ç³»çµ±
        if FILTER_CACHE_AVAILABLE:
            cache_dir = self.config.get('filter', 'cache_dir', fallback='.filter_cache')
            self.filter_cache = FilterCache(cache_dir)
            logger.info(f"ç·©å­˜ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼Œç·©å­˜ç›®éŒ„: {cache_dir}")
        else:
            self.filter_cache = None
            logger.warning("ç·©å­˜ç³»çµ±ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨å‚³çµ±æƒææ¨¡å¼")
        
        # çµæœå­˜å„²
        self.curation_results = {}
        self.processing_metadata = {
            "source_file": self.config.get('excel', 'file_path'),
            "sheet_name": self.config.get('excel', 'sheet_name'),
            "llm_model": self._get_llm_model_display_name(),
            "processing_start_time": datetime.now().isoformat(),
            "total_processed": 0,
            "total_success": 0,
            "total_failed": 0,
            "processing_mode": "unknown"
        }
        
        logger.info("ä½›å­¸å•ç­”ç²¾é¸å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def setup_openai(self):
        """è¨­ç½®OpenAI APIæˆ–ChatMock"""
        # å„ªå…ˆä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®æ–‡ä»¶
        if self.api_type:
            api_type = self.api_type.lower()
        else:
            api_type = self.config.get('api', 'type', fallback='openai').lower()
        
        logger.info(f"ä½¿ç”¨APIé¡å‹: {api_type}")
        
        if api_type == 'chatmock':
            self._setup_chatmock()
        else:
            self._setup_openai_api()
    
    def _setup_chatmock(self):
        """è¨­ç½®ChatMockæœ¬åœ°æœå‹™å™¨"""
        try:
            # å„ªå…ˆä½¿ç”¨å‘½ä»¤è¡Œåƒæ•¸ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®æ–‡ä»¶
            if self.chatmock_url:
                base_url = self.chatmock_url
            else:
                base_url = self.config.get('chatmock', 'base_url', fallback='http://127.0.0.1:8000/v1')
            
            model = self.config.get('chatmock', 'model', fallback='gpt-5')
            
            # å‰µå»ºOpenAIå®¢æˆ¶ç«¯å¯¦ä¾‹ï¼ŒæŒ‡å‘ChatMockæœå‹™å™¨
            self.client = OpenAI(
                base_url=base_url,
                api_key="chatmock"  # ChatMockå¿½ç•¥æ­¤å€¼
            )
            self.model = model
            
            # ChatMockä½¿ç”¨GPT-5åƒæ•¸
            self.temperature, self.max_tokens = self._get_model_specific_params()
            
            logger.info(f"ChatMockè¨­ç½®å®Œæˆ - æœå‹™å™¨: {base_url}")
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.model}")
            logger.info(f"ä½¿ç”¨åƒæ•¸ - æº«åº¦: {self.temperature}, æœ€å¤§Token: {self.max_tokens}")
            
        except Exception as e:
            logger.error(f"ChatMockè¨­ç½®å¤±æ•—: {e}")
            raise ValueError(f"ChatMockè¨­ç½®å¤±æ•—: {e}")
    
    def _setup_openai_api(self):
        """è¨­ç½®OpenAIå®˜æ–¹API"""
        # å„ªå…ˆä½¿ç”¨å‚³å…¥çš„API key
        if self.api_key:
            api_key = self.api_key
        else:
            # å˜—è©¦å¾ç’°å¢ƒè®Šé‡ç²å–
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                # æœ€å¾Œå˜—è©¦å¾é…ç½®æ–‡ä»¶ç²å–ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
                api_key = self.config.get('openai', 'api_key', fallback=None)
        
        if not api_key or api_key == 'YOUR_OPENAI_API_KEY_HERE':
            raise ValueError(
                "è«‹é€šéä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è¨­ç½®OpenAI API Key:\n"
                "1. å‘½ä»¤è¡Œåƒæ•¸: --api-key YOUR_API_KEY\n"
                "2. ç’°å¢ƒè®Šé‡: export OPENAI_API_KEY=YOUR_API_KEY\n"
                "3. é…ç½®æ–‡ä»¶: åœ¨config.iniä¸­è¨­ç½®api_keyï¼ˆä¸æ¨è–¦ï¼‰"
            )
        
        # å‰µå»ºOpenAIå®¢æˆ¶ç«¯å¯¦ä¾‹
        self.client = OpenAI(api_key=api_key)
        self.model = self.config.get('openai', 'model', fallback='gpt-4')
        
        # æ ¹æ“šæ¨¡å‹é¡å‹è‡ªå‹•é¸æ“‡åƒæ•¸é…ç½®
        self.temperature, self.max_tokens = self._get_model_specific_params()
        
        logger.info(f"OpenAIè¨­ç½®å®Œæˆ - æ¨¡å‹: {self.model}")
        logger.info(f"ä½¿ç”¨åƒæ•¸ - æº«åº¦: {self.temperature}, æœ€å¤§Token: {self.max_tokens}")
    
    def _get_model_specific_params(self) -> tuple:
        """æ ¹æ“šæ¨¡å‹é¡å‹ç²å–å°æ‡‰çš„åƒæ•¸é…ç½®"""
        try:
            if self.model.startswith('gpt-5'):
                # GPT-5ç³»åˆ—æ¨¡å‹åƒæ•¸
                
                # GPT-5ä¸æ”¯æŒè‡ªå®šç¾©temperatureï¼Œä½¿ç”¨é»˜èªå€¼1
                temperature = 1.0
                
                # å˜—è©¦è®€å–max_completion_tokensï¼Œä½†ä¸å¼·åˆ¶è¦æ±‚
                try:
                    max_tokens = self.config.getint('gpt5_models', 'max_completion_tokens', fallback=None)
                    if max_tokens is not None:
                        logger.warning("æª¢æ¸¬åˆ°max_completion_tokensè¨­ç½®ï¼Œä½†å»ºè­°ä¸è¨­ç½®ä»¥é¿å…ç©ºå›æ‡‰")
                except:
                    max_tokens = None
                
                logger.info(f"ä½¿ç”¨GPT-5å°ˆç”¨åƒæ•¸é…ç½®")
                
            else:
                # GPT-4ç³»åˆ—æ¨¡å‹åƒæ•¸
                logger.info("ä½¿ç”¨GPT-4å°ˆç”¨åƒæ•¸é…ç½®")
                
                temperature = self.config.getfloat('gpt4_models', 'temperature', fallback=0.3)
                max_tokens = self.config.getint('gpt4_models', 'max_tokens', fallback=1000)
            
            return temperature, max_tokens
            
        except Exception as e:
            logger.error(f"ç²å–æ¨¡å‹ç‰¹å®šåƒæ•¸å¤±æ•—: {e}")
            logger.warning("ä½¿ç”¨é»˜èªåƒæ•¸é…ç½®")
            return 0.3, 1000
    
    def _get_llm_model_display_name(self) -> str:
        """ç²å–LLMæ¨¡å‹çš„é¡¯ç¤ºåç¨±ï¼Œæ ¹æ“šAPIé¡å‹å‹•æ…‹è¨­ç½®"""
        try:
            # ç²å–ç•¶å‰APIé¡å‹
            if self.api_type:
                api_type = self.api_type.lower()
            else:
                api_type = self.config.get('api', 'type', fallback='openai').lower()
            
            if api_type == 'chatmock':
                # ChatMockæ¨¡å¼ï¼šä½¿ç”¨ChatMocké…ç½®çš„æ¨¡å‹åç¨±
                model = self.config.get('chatmock', 'model', fallback='gpt-5')
                return f"chat-{model}"  # ä¾‹å¦‚ï¼šchat-gpt-5
            else:
                # OpenAIæ¨¡å¼ï¼šä½¿ç”¨OpenAIé…ç½®çš„æ¨¡å‹åç¨±
                model = self.config.get('openai', 'model', fallback='gpt-4')
                return model  # ä¾‹å¦‚ï¼šgpt-5-nano
            
        except Exception as e:
            logger.error(f"ç²å–æ¨¡å‹é¡¯ç¤ºåç¨±å¤±æ•—: {e}")
            # è¿”å›é»˜èªå€¼
            return "gpt-4"
    
    def load_prompt_template(self) -> str:
        """è¼‰å…¥promptæ¨¡æ¿"""
        prompt_file = 'prompt_template.txt'
        
        if not os.path.exists(prompt_file):
            logger.warning(f"Promptæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
            return self.get_default_prompt()
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"è¼‰å…¥promptæ¨¡æ¿å¤±æ•—: {e}")
            return self.get_default_prompt()
    
    def get_default_prompt(self) -> str:
        """ç²å–é»˜èªpromptæ¨¡æ¿"""
        return """ä½ æ˜¯ä¸€å€‹ä½›å­¸å°ˆå®¶ï¼Œå°ˆé–€è² è²¬å°ä½›å­¸å•ç­”é€²è¡Œç²¾é¸è©•åˆ†ã€‚

è«‹æ ¹æ“šä»¥ä¸‹è©•åˆ†æ¨™æº–ï¼Œå°çµ¦å®šçš„å•ç­”å…§å®¹é€²è¡Œè©•åˆ†ï¼š

**å•é¡Œï¼š** {title}
**å›ç­”ï¼š** {answer}

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

âœ… **å»£åº¦è©•åˆ†ï¼š** XXåˆ†
âœ… **æ·±åº¦è©•åˆ†ï¼š** XXåˆ†  
âœ… **ç¶œåˆè©•åˆ†ï¼š** XXåˆ†
âœ… **å»£åº¦è©•è«–ï¼š** (100å­—ä»¥å…§)
âœ… **æ·±åº¦è©•è«–ï¼š** (100å­—ä»¥å…§)
âœ… **ç¸½é«”è©•åƒ¹ï¼š** (80å­—ä»¥å…§)
âœ… **å•é¡Œæ‘˜è¦ï¼š** (50å­—ä»¥å…§)
âœ… **å›ç­”æ‘˜è¦ï¼š** (100å­—ä»¥å…§)"""

    def load_excel_data(self) -> Tuple[openpyxl.Workbook, openpyxl.worksheet.worksheet.Worksheet]:
        """è¼‰å…¥Excelæ•¸æ“š"""
        file_path = self.config.get('excel', 'file_path')
        sheet_name = self.config.get('excel', 'sheet_name')
        
        try:
            workbook = load_workbook(file_path, read_only=True)
            worksheet = workbook[sheet_name]
            logger.info(f"æˆåŠŸè¼‰å…¥Excelæ–‡ä»¶: {file_path}, å·¥ä½œè¡¨: {sheet_name}")
            return workbook, worksheet
        except Exception as e:
            logger.error(f"è¼‰å…¥Excelæ–‡ä»¶å¤±æ•—: {e}")
            raise

    def extract_qa_content(self, worksheet, row: int) -> Tuple[str, str]:
        """æå–å•ç­”å…§å®¹"""
        # æ ¹æ“šExcelçµæ§‹èª¿æ•´åˆ—è™Ÿ
        question_col = self.config.getint('excel', 'question_column')
        answer_col = self.config.getint('excel', 'answer_column')
        
        try:
            question = worksheet.cell(row=row, column=question_col).value or ""
            answer = worksheet.cell(row=row, column=answer_col).value or ""
            
            return str(question).strip(), str(answer).strip()
        except Exception as e:
            logger.error(f"æå–ç¬¬ {row} è¡Œå…§å®¹å¤±æ•—: {e}")
            return "", ""

    def evaluate_qa_quality(self, question: str, answer: str) -> Dict[str, Any]:
        """è©•ä¼°å•ç­”è³ªé‡"""
        try:
            # è¨˜éŒ„é–‹å§‹æ™‚é–“
            start_time = time.time()
            logger.info(f"ğŸ¤– é–‹å§‹AIè©•åˆ†ï¼Œå•é¡Œé•·åº¦: {len(question)}å­—ï¼Œç­”æ¡ˆé•·åº¦: {len(answer)}å­—")
            
            # æ ¼å¼åŒ–æç¤ºè©
            prompt_start = time.time()
            formatted_prompt = self.prompt_template.format(title=question, answer=answer)
            prompt_time = time.time() - prompt_start
            logger.info(f"ğŸ“ æç¤ºè©æ ¼å¼åŒ–å®Œæˆï¼Œè€—æ™‚: {prompt_time:.2f}ç§’")
            
            # æº–å‚™APIåƒæ•¸
            api_params = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': formatted_prompt}],
                'temperature': self.temperature,
                'max_tokens': self.max_tokens
            }
            
            if self.max_tokens:
                api_params['max_tokens'] = self.max_tokens
            
            logger.info(f"ğŸ”§ APIåƒæ•¸æº–å‚™å®Œæˆ: æ¨¡å‹={self.model}, æº«åº¦={self.temperature}")
            
            # åŸ·è¡ŒAPIèª¿ç”¨
            logger.info(f"ğŸŒ é–‹å§‹APIèª¿ç”¨...")
            api_start = time.time()
            
            # æ·»åŠ é‡è©¦æ©Ÿåˆ¶
            max_retries = 3
            retry_count = 0
            last_error = None
            
            while retry_count < max_retries:
                try:
                    if retry_count > 0:
                        logger.info(f"ğŸ”„ ç¬¬ {retry_count} æ¬¡é‡è©¦...")
                        time.sleep(2 ** retry_count)  # æŒ‡æ•¸é€€é¿
                    
                    response = self.client.chat.completions.create(**api_params)
                    api_time = time.time() - api_start
                    logger.info(f"âœ… APIèª¿ç”¨æˆåŠŸï¼Œè€—æ™‚: {api_time:.2f}ç§’")
                    
                    # æª¢æŸ¥éŸ¿æ‡‰
                    if not response.choices or not response.choices[0].message:
                        raise ValueError("APIéŸ¿æ‡‰æ ¼å¼ç•°å¸¸")
                    
                    content = response.choices[0].message.content
                    logger.info(f"ğŸ“„ æ”¶åˆ°AIéŸ¿æ‡‰ï¼Œé•·åº¦: {len(content)}å­—ç¬¦")
                    
                    # è§£æçµæœ
                    logger.info(f"ğŸ” é–‹å§‹è§£æLLMè©•åˆ†çµæœ...")
                    parse_start = time.time()
                    parsed_result = self.parse_evaluation_result(content)
                    parse_time = time.time() - parse_start
                    
                    # çµ±è¨ˆè§£æçµæœ
                    success_fields = sum(1 for v in parsed_result.values() if v != 'è§£æå¤±æ•—')
                    total_fields = len(parsed_result)
                    logger.info(f"âœ… è§£æå®Œæˆ: {success_fields}/{total_fields} å€‹å­—æ®µæˆåŠŸï¼Œè€—æ™‚: {parse_time:.2f}ç§’")
                    
                    # è¨ˆç®—ç¸½è€—æ™‚
                    total_time = time.time() - start_time
                    logger.info(f"ğŸ¯ è©•åˆ†å®Œæˆï¼Œç¸½è€—æ™‚: {total_time:.2f}ç§’")
                    
                    return parsed_result
                    
                except Exception as e:
                    last_error = e
                    retry_count += 1
                    api_time = time.time() - api_start
                    
                    if retry_count < max_retries:
                        logger.warning(f"âš ï¸ APIèª¿ç”¨å¤±æ•— (ç¬¬{retry_count}æ¬¡): {e}")
                        logger.warning(f"â±ï¸ å·²è€—æ™‚: {api_time:.2f}ç§’ï¼Œæº–å‚™é‡è©¦...")
                    else:
                        logger.error(f"âŒ APIèª¿ç”¨æœ€çµ‚å¤±æ•—ï¼Œå·²é‡è©¦{max_retries}æ¬¡: {e}")
                        logger.error(f"â±ï¸ ç¸½è€—æ™‚: {api_time:.2f}ç§’")
                        break
            
            # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—äº†
            logger.error(f"ğŸ’¥ AIè©•åˆ†å®Œå…¨å¤±æ•—ï¼Œè¿”å›éŒ¯èª¤çµæœ")
            return {
                'breadth_score': 'APIèª¿ç”¨å¤±æ•—',
                'depth_score': 'APIèª¿ç”¨å¤±æ•—',
                'uniqueness_score': 'APIèª¿ç”¨å¤±æ•—',
                'overall_score': 'APIèª¿ç”¨å¤±æ•—',
                'breadth_comment': f'APIèª¿ç”¨å¤±æ•—: {str(last_error)}',
                'depth_comment': f'APIèª¿ç”¨å¤±æ•—: {str(last_error)}',
                'uniqueness_comment': f'APIèª¿ç”¨å¤±æ•—: {str(last_error)}',
                'overall_comment': f'APIèª¿ç”¨å¤±æ•—: {str(last_error)}',
                'question_summary': 'APIèª¿ç”¨å¤±æ•—',
                'answer_summary': 'APIèª¿ç”¨å¤±æ•—',
                'status': 'error'
            }
            
        except Exception as e:
            logger.error(f"âŒ è©•åˆ†éç¨‹ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
            return {
                'breadth_score': 'ç³»çµ±éŒ¯èª¤',
                'depth_score': 'ç³»çµ±éŒ¯èª¤',
                'uniqueness_score': 'ç³»çµ±éŒ¯èª¤',
                'overall_score': 'ç³»çµ±éŒ¯èª¤',
                'breadth_comment': f'ç³»çµ±éŒ¯èª¤: {str(e)}',
                'depth_comment': f'ç³»çµ±éŒ¯èª¤: {str(e)}',
                'uniqueness_comment': f'ç³»çµ±éŒ¯èª¤: {str(e)}',
                'overall_comment': f'ç³»çµ±éŒ¯èª¤: {str(e)}',
                'question_summary': 'ç³»çµ±éŒ¯èª¤',
                'answer_summary': 'ç³»çµ±éŒ¯èª¤',
                'status': 'error'
            }

    def parse_evaluation_result(self, result_text: str) -> Dict:
        """è§£æLLMçš„è©•åˆ†çµæœ"""
        try:
            logger.info("é–‹å§‹è§£æLLMè©•åˆ†çµæœ...")
            logger.debug(f"åŸå§‹çµæœæ–‡æœ¬é•·åº¦: {len(result_text)}")
            logger.debug(f"åŸå§‹çµæœæ–‡æœ¬å‰500å­—ç¬¦: {result_text[:500]}")
            
            # åˆå§‹åŒ–çµæœå­—å…¸
            parsed_result = {
                'breadth_score': 'è§£æå¤±æ•—',
                'depth_score': 'è§£æå¤±æ•—', 
                'uniqueness_score': 'è§£æå¤±æ•—',
                'overall_score': 'è§£æå¤±æ•—',
                'breadth_comment': 'è§£æå¤±æ•—',
                'depth_comment': 'è§£æå¤±æ•—',
                'uniqueness_comment': 'è§£æå¤±æ•—',
                'overall_comment': 'è§£æå¤±æ•—',
                'question_summary': 'è§£æå¤±æ•—',
                'answer_summary': 'è§£æå¤±æ•—',
                'status': 'success'  # æ·»åŠ ç‹€æ…‹å­—æ®µ
            }
            
            # æ”¹é€²çš„æ­£å‰‡è¡¨é”å¼ï¼ŒåŒ¹é…LLMçš„å¯¦éš›è¼¸å‡ºæ ¼å¼ï¼ˆæ”¯æŒå¤šç¨®æ ¼å¼ï¼‰
            patterns = {
                'breadth_score': [
                    r'âœ… \*\*å»£åº¦è©•åˆ†ï¼š\*\* (\d+)åˆ†',  # ç¹é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… å»£åº¦è©•åˆ†ï¼š(\d+)åˆ†',           # ç¹é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                    r'âœ… \*\*å¹¿åº¦è¯„åˆ†ï¼š\*\* (\d+)åˆ†',  # ç°¡é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… å¹¿åº¦è¯„åˆ†ï¼š(\d+)åˆ†'            # ç°¡é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                ],
                'depth_score': [
                    r'âœ… \*\*æ·±åº¦è©•åˆ†ï¼š\*\* (\d+)åˆ†',  # ç¹é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… æ·±åº¦è©•åˆ†ï¼š(\d+)åˆ†',           # ç¹é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                    r'âœ… \*\*æ·±åº¦è¯„åˆ†ï¼š\*\* (\d+)åˆ†',  # ç°¡é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… æ·±åº¦è¯„åˆ†ï¼š(\d+)åˆ†'            # ç°¡é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                ],
                'uniqueness_score': [
                    r'âœ… \*\*ç¨ç‰¹æ€§è©•åˆ†ï¼š\*\* (\d+)åˆ†',  # ç¹é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… ç¨ç‰¹æ€§è©•åˆ†ï¼š(\d+)åˆ†',           # ç¹é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                    r'âœ… \*\*ç‹¬ç‰¹æ€§è¯„åˆ†ï¼š\*\* (\d+)åˆ†',  # ç°¡é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… ç‹¬ç‰¹æ€§è¯„åˆ†ï¼š(\d+)åˆ†'            # ç°¡é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                ],
                'overall_score': [
                    r'âœ… \*\*ç¶œåˆè©•åˆ†ï¼š\*\* (\d+)åˆ†',  # ç¹é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… ç¶œåˆè©•åˆ†ï¼š(\d+)åˆ†',           # ç¹é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                    r'âœ… \*\*ç»¼åˆè¯„åˆ†ï¼š\*\* (\d+)åˆ†',  # ç°¡é«”ä¸­æ–‡ï¼Œæœ‰**æ¨™è¨˜
                    r'âœ… ç»¼åˆè¯„åˆ†ï¼š(\d+)åˆ†'            # ç°¡é«”ä¸­æ–‡ï¼Œç„¡**æ¨™è¨˜
                ],
                'breadth_comment': [
                    r'âœ… \*\*å»£åº¦è©•è«–ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… å»£åº¦è©•è«–ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*å¹¿åº¦è¯„è®ºï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… å¹¿åº¦è¯„è®ºï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ],
                'depth_comment': [
                    r'âœ… \*\*æ·±åº¦è©•è«–ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… æ·±åº¦è©•è«–ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*æ·±åº¦è¯„è®ºï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… æ·±åº¦è¯„è®ºï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ],
                'uniqueness_comment': [
                    r'âœ… \*\*ç¨ç‰¹æ€§è©•è«–ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… ç¨ç‰¹æ€§è©•è«–ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*ç‹¬ç‰¹æ€§è¯„è®ºï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… ç‹¬ç‰¹æ€§è¯„è®ºï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ],
                'overall_comment': [
                    r'âœ… \*\*ç¸½é«”è©•åƒ¹ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… ç¸½é«”è©•åƒ¹ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*æ€»ä½“è¯„ä»·ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… æ€»ä½“è¯„ä»·ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ],
                'question_summary': [
                    r'âœ… \*\*å•é¡Œæ‘˜è¦ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… å•é¡Œæ‘˜è¦ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*é—®é¢˜æ‘˜è¦ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… é—®é¢˜æ‘˜è¦ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ],
                'answer_summary': [
                    r'âœ… \*\*å›ç­”æ‘˜è¦ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… å›ç­”æ‘˜è¦ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… \*\*å›ç­”æ‘˜è¦ï¼š\*\*\s*\n(.+?)(?=\n\n|âœ…|$)',
                    r'âœ… å›ç­”æ‘˜è¦ï¼š\s*\n(.+?)(?=\n\n|âœ…|$)'
                ]
            }
            
            # å˜—è©¦è§£ææ¯å€‹å­—æ®µ
            for field, pattern_list in patterns.items():
                found_match = False
                for pattern in pattern_list:
                    try:
                        match = re.search(pattern, result_text, re.DOTALL | re.MULTILINE)
                        if match:
                            if 'score' in field:
                                # åˆ†æ•¸å­—æ®µ
                                parsed_result[field] = int(match.group(1))
                                logger.debug(f"æˆåŠŸè§£æ {field}: {parsed_result[field]}")
                            else:
                                # è©•è«–å’Œæ‘˜è¦å­—æ®µ
                                parsed_result[field] = match.group(1).strip()
                                logger.debug(f"æˆåŠŸè§£æ {field}: {parsed_result[field][:50]}...")
                            found_match = True
                            break # æ‰¾åˆ°åŒ¹é…å¾Œç«‹å³é€€å‡ºå…§å±¤å¾ªç’°
                    except Exception as e:
                        logger.warning(f"å˜—è©¦æ¨¡å¼ '{pattern}' è§£æ {field} å¤±æ•—: {e}")
                        continue
                
                if not found_match:
                    logger.warning(f"æœªæ‰¾åˆ° {field} çš„åŒ¹é…")
                    # å˜—è©¦æ›´å¯¬é¬†çš„åŒ¹é…
                    if 'score' in field:
                        # å˜—è©¦å…¶ä»–å¯èƒ½çš„æ ¼å¼
                        alt_patterns = [
                            rf'{field.replace("_", "")}.*?(\d+)',
                            rf'{field.replace("_", "")}.*?(\d+)',
                            rf'(\d+).*?{field.replace("_", "")}'
                        ]
                        for alt_pattern in alt_patterns:
                            alt_match = re.search(alt_pattern, result_text, re.IGNORECASE)
                            if alt_match:
                                parsed_result[field] = int(alt_match.group(1))
                                logger.info(f"ä½¿ç”¨å‚™ç”¨æ¨¡å¼æˆåŠŸè§£æ {field}: {parsed_result[field]}")
                                break
                    else:
                        # å˜—è©¦æ›´å¯¬é¬†çš„æ–‡æœ¬åŒ¹é…
                        alt_patterns = [
                            rf'{field.replace("_", "")}.*?([^\n]+)',
                            rf'([^\n]+).*?{field.replace("_", "")}'
                        ]
                        for alt_pattern in alt_patterns:
                            alt_match = re.search(alt_pattern, result_text, re.IGNORECASE)
                            if alt_match:
                                parsed_result[field] = alt_match.group(1).strip()
                                logger.info(f"ä½¿ç”¨å‚™ç”¨æ¨¡å¼æˆåŠŸè§£æ {field}: {parsed_result[field][:50]}...")
                                break
            
            # è¨ˆç®—ç¶œåˆè©•åˆ†ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
            try:
                breadth = int(parsed_result['breadth_score'])
                depth = int(parsed_result['depth_score'])
                uniqueness = int(parsed_result['uniqueness_score'])
                
                # åŠ æ¬Šå¹³å‡ï¼šå»£åº¦30%ï¼Œæ·±åº¦40%ï¼Œç¨ç‰¹æ€§30%
                overall_score = breadth * 0.3 + depth * 0.4 + uniqueness * 0.3
                parsed_result['overall_score'] = round(overall_score)
                logger.info(f"âœ… ç¶œåˆè©•åˆ†è¨ˆç®—å®Œæˆ: {breadth}Ã—0.3 + {depth}Ã—0.4 + {uniqueness}Ã—0.3 = {overall_score:.1f} â†’ {parsed_result['overall_score']}")
                
            except (ValueError, TypeError) as e:
                logger.warning(f"âš ï¸ ç¶œåˆè©•åˆ†è¨ˆç®—å¤±æ•—: {e}")
                parsed_result['overall_score'] = 'è¨ˆç®—å¤±æ•—'
            
            # æª¢æŸ¥è§£æçµæœ
            success_count = sum(1 for v in parsed_result.values() if v != 'è§£æå¤±æ•—')
            total_count = len(parsed_result)
            logger.info(f"è§£æå®Œæˆ: {success_count}/{total_count} å€‹å­—æ®µæˆåŠŸ")
            
            if success_count == 0:
                logger.error("æ‰€æœ‰å­—æ®µè§£æå¤±æ•—ï¼Œè«‹æª¢æŸ¥LLMè¼¸å‡ºæ ¼å¼")
                logger.error(f"å®Œæ•´çµæœæ–‡æœ¬: {result_text}")
            
            return parsed_result
            
        except Exception as e:
            logger.error(f"è§£æè©•åˆ†çµæœå¤±æ•—: {e}")
            return {
                'breadth_score': 'è§£æå¤±æ•—',
                'depth_score': 'è§£æå¤±æ•—',
                'uniqueness_score': 'è§£æå¤±æ•—',
                'overall_score': 'è§£æå¤±æ•—', 
                'breadth_comment': 'è§£æå¤±æ•—',
                'depth_comment': 'è§£æå¤±æ•—',
                'uniqueness_comment': 'è§£æå¤±æ•—',
                'overall_comment': 'è§£æå¤±æ•—',
                'question_summary': 'è§£æå¤±æ•—',
                'answer_summary': 'è§£æå¤±æ•—'
            }

    def load_existing_results(self, results_file: str) -> Dict:
        """è¼‰å…¥å·²æœ‰çš„ç²¾é¸è©•åˆ†çµæœ"""
        if not os.path.exists(results_file):
            return {}
        
        try:
            with open(results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('results', {})
        except Exception as e:
            logger.error(f"è¼‰å…¥å·²æœ‰çµæœå¤±æ•—: {e}")
            return {}

    def save_results(self, results_file: str):
        """ä¿å­˜ç²¾é¸è©•åˆ†çµæœåˆ°JSONæ–‡ä»¶"""
        try:
            self.processing_metadata['processing_end_time'] = datetime.now().isoformat()
            self.processing_metadata['total_processed'] = len(self.curation_results)
            self.processing_metadata['total_success'] = sum(1 for r in self.curation_results.values() if r.get('status') == 'success')
            self.processing_metadata['total_failed'] = len(self.curation_results) - self.processing_metadata['total_success']
            
            output_data = {
                'metadata': self.processing_metadata,
                'results': self.curation_results
            }
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"çµæœå·²ä¿å­˜åˆ°: {results_file}")
            logger.info(f"ç¸½è™•ç†: {self.processing_metadata['total_processed']}, æˆåŠŸ: {self.processing_metadata['total_success']}, å¤±æ•—: {self.processing_metadata['total_failed']}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜çµæœå¤±æ•—: {e}")

    def _get_filter_conditions(self) -> Dict:
        """ç²å–éæ¿¾æ¢ä»¶"""
        try:
            conditions = {}
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ç‰¹å®šçš„éæ¿¾æ¢ä»¶
            if self.config.has_section('filter'):
                # åˆ—å€¼éæ¿¾æ¢ä»¶ï¼ˆåŸºæ–¼Excelåˆ—Fã€Gã€Hçš„å€¼ï¼‰
                if self.config.has_option('filter', 'column_f_value'):
                    column_f_value = self.config.get('filter', 'column_f_value')
                    if column_f_value:
                        conditions['column_f_value'] = column_f_value.strip()
                
                if self.config.has_option('filter', 'column_g_value'):
                    column_g_value = self.config.get('filter', 'column_g_value')
                    if column_g_value:
                        conditions['column_g_value'] = column_g_value.strip()
                
                if self.config.has_option('filter', 'column_h_value'):
                    column_h_value = self.config.get('filter', 'column_h_value')
                    if column_h_value:
                        conditions['column_h_value'] = column_h_value.strip()
                
                # æª¢æŸ¥æ˜¯å¦è‡³å°‘è¨­ç½®äº†ä¸€å€‹åˆ—å€¼éæ¿¾æ¢ä»¶
                if not any(key in conditions for key in ['column_f_value', 'column_g_value', 'column_h_value']):
                    logger.warning("éæ¿¾æ¨¡å¼ä¸‹æœªè¨­ç½®ä»»ä½•åˆ—å€¼éæ¿¾æ¢ä»¶ï¼Œå»ºè­°è¨­ç½®è‡³å°‘ä¸€å€‹åˆ—å€¼")
            
            return conditions
            
        except Exception as e:
            logger.error(f"ç²å–éæ¿¾æ¢ä»¶å¤±æ•—: {e}")
            return {}

    def get_filtered_rows(self, worksheet) -> List[int]:
        """ç²å–éæ¿¾å¾Œçš„è¡Œè™Ÿåˆ—è¡¨"""
        try:
            # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨éæ¿¾æ¨¡å¼
            use_filter_mode = self.config.getboolean('processing', 'use_filter_mode', fallback=False)
            if not use_filter_mode:
                return []
            
            logger.info("é–‹å§‹åŸ·è¡Œéæ¿¾æ¨¡å¼...")
            
            # ç²å–éæ¿¾æ¢ä»¶
            filter_conditions = self._get_filter_conditions()
            logger.info(f"éæ¿¾æ¢ä»¶: {filter_conditions}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åˆ—å€¼éæ¿¾æ¢ä»¶
            has_column_filters = any(key in filter_conditions for key in ['column_f_value', 'column_g_value', 'column_h_value'])
            
            if has_column_filters:
                # ä½¿ç”¨å¿«é€Ÿéæ¿¾æ¨¡å¼
                logger.info("ä½¿ç”¨å¿«é€Ÿåˆ—å€¼éæ¿¾æ¨¡å¼...")
                filtered_rows = self._fast_column_filter(worksheet, filter_conditions)
            else:
                # ä½¿ç”¨å‚³çµ±æƒææ¨¡å¼
                logger.info("ä½¿ç”¨å‚³çµ±æƒææ¨¡å¼...")
                filtered_rows = self._traditional_scan_filter(worksheet)
            
            logger.info(f"éæ¿¾å®Œæˆï¼Œå…±æ‰¾åˆ° {len(filtered_rows)} è¡Œ")
            
            # è¨˜éŒ„éæ¿¾çµæœçš„è©³ç´°ä¿¡æ¯
            if filtered_rows:
                logger.info(f"éæ¿¾çµæœè¡Œè™Ÿ: {filtered_rows[:10]}{'...' if len(filtered_rows) > 10 else ''}")
            
            return filtered_rows
            
        except Exception as e:
            logger.error(f"ç²å–éæ¿¾è¡Œå¤±æ•—: {e}")
            return []

    def _fast_column_filter(self, worksheet, conditions: Dict) -> List[int]:
        """å¿«é€Ÿåˆ—å€¼éæ¿¾æ¨¡å¼ - å¾Column Hé–‹å§‹åˆ¤æ–·ä»¥æé«˜æ•ˆç‡"""
        try:
            logger.info("é–‹å§‹å¿«é€Ÿåˆ—å€¼éæ¿¾ï¼ˆå¾Column Hé–‹å§‹ï¼‰...")
            
            # æª¢æŸ¥ç·©å­˜
            if self.filter_cache:
                excel_file = self.config.get('excel', 'file_path')
                f_value = conditions.get('column_f_value', '')
                g_value = conditions.get('column_g_value', '')
                h_value = conditions.get('column_h_value', '')
                
                cached_rows = self.filter_cache.get_cached_result(excel_file, f_value, g_value, h_value)
                if cached_rows:
                    logger.info(f"ç·©å­˜å‘½ä¸­ï¼ç›´æ¥è¿”å› {len(cached_rows)} è¡Œéæ¿¾çµæœ")
                    return cached_rows
                else:
                    logger.info("ç·©å­˜æœªå‘½ä¸­ï¼Œé–‹å§‹æƒæExcelæ–‡ä»¶")
            
            # è¨˜éŒ„ä½¿ç”¨çš„éæ¿¾æ¢ä»¶
            used_conditions = []
            if 'column_f_value' in conditions:
                used_conditions.append(f"Fåˆ—={conditions['column_f_value']}")
            if 'column_g_value' in conditions:
                used_conditions.append(f"Gåˆ—={conditions['column_g_value']}")
            if 'column_h_value' in conditions:
                used_conditions.append(f"Håˆ—={conditions['column_h_value']}")
            
            logger.info(f"ä½¿ç”¨çš„åˆ—å€¼éæ¿¾æ¢ä»¶: {', '.join(used_conditions)}")
            
            # ç²å–è©•åˆ†ç¯„åœè¨­å®š
            start_index = self.config.getint('filter', 'start_index', fallback=0)
            end_index = self.config.getint('filter', 'end_index', fallback=0)
            score_all_filtered = self.config.getboolean('filter', 'score_all_filtered', fallback=False)
            
            # è¨ˆç®—éœ€è¦çš„éæ¿¾æ¢ç›®æ•¸é‡
            if score_all_filtered:
                # å…¨éƒ¨è©•åˆ†æ¨¡å¼
                required_count = float('inf')  # ç„¡é™å¤§ï¼Œè¡¨ç¤ºéœ€è¦æ‰€æœ‰çµæœ
                logger.info(f"è©•åˆ†è¨­å®š: å…¨éƒ¨è©•åˆ†æ¨¡å¼ï¼Œå°‡è©•åˆ†æ‰€æœ‰éæ¿¾çµæœ")
            elif end_index == 0:
                # åªè©•åˆ†ç¬¬ä¸€æ¢
                required_count = 1
                logger.info(f"è©•åˆ†è¨­å®š: åªè©•åˆ†ç¬¬ä¸€æ¢éæ¿¾çµæœ")
            else:
                # è©•åˆ†æŒ‡å®šç¯„åœ
                required_count = end_index - start_index + 1
                logger.info(f"è©•åˆ†è¨­å®š: è©•åˆ†ç¬¬{start_index}åˆ°ç¬¬{end_index}æ¢éæ¿¾çµæœï¼Œå…±éœ€{required_count}æ¢")
            
            # ç›´æ¥è®€å–åˆ—Fã€Gã€Hçš„å€¼é€²è¡Œéæ¿¾
            max_row = worksheet.max_row
            logger.info(f"Excelç¸½è¡Œæ•¸: {max_row}")
            
            # å¾ç¬¬7è¡Œé–‹å§‹æƒæï¼ˆè·³éæ¨™é¡Œè¡Œå’Œèªªæ˜è¡Œï¼‰
            scan_start = 7
            
            # æ ¹æ“šé…ç½®æ±ºå®šæƒæç¯„åœ
            scan_full_file = self.config.getboolean('filter', 'scan_full_file', fallback=True)
            if scan_full_file:
                scan_end = max_row  # æƒæå®Œæ•´æ–‡ä»¶ä»¥å»ºç«‹å®Œæ•´ç·©å­˜
                logger.info("ğŸ” æƒæç­–ç•¥: å®Œæ•´æ–‡ä»¶æƒæï¼ˆå»ºç«‹å®Œæ•´ç·©å­˜ï¼‰")
            else:
                scan_end = min(max_row, 1000)  # é™åˆ¶æƒæç¯„åœä»¥æ§åˆ¶æ€§èƒ½
                logger.info("âš ï¸ æƒæç­–ç•¥: é™åˆ¶æƒæç¯„åœï¼ˆç·©å­˜ä¸å®Œæ•´ï¼Œä¸æ¨è–¦ï¼‰")
            
            logger.info(f"æƒæç¯„åœ: ç¬¬{scan_start}è¡Œåˆ°ç¬¬{scan_end}è¡Œ")
            logger.info(f"é è¨ˆæƒæè¡Œæ•¸: {scan_end - scan_start + 1}")
            
            # è¨ˆç®—é æœŸçš„é€²åº¦æ›´æ–°é»ï¼ˆæ ¹æ“šæ–‡ä»¶å¤§å°å‹•æ…‹èª¿æ•´ï¼‰
            expected_progress_points = []
            if scan_end - scan_start > 1000:
                # å¤§æ–‡ä»¶ï¼šæ¯500è¡Œæ›´æ–°ä¸€æ¬¡
                step = 500
            elif scan_end - scan_start > 500:
                # ä¸­ç­‰æ–‡ä»¶ï¼šæ¯200è¡Œæ›´æ–°ä¸€æ¬¡
                step = 200
            else:
                # å°æ–‡ä»¶ï¼šæ¯100è¡Œæ›´æ–°ä¸€æ¬¡
                step = 100
            
            for i in range(step, scan_end + 1, step):
                if i >= scan_start:
                    expected_progress_points.append(i)
            
            logger.info(f"é€²åº¦æ›´æ–°é »ç‡: æ¯{step}è¡Œï¼Œé æœŸé€²åº¦æ›´æ–°é»: {expected_progress_points[:10]}{'...' if len(expected_progress_points) > 10 else ''}")
            
            # è¨˜éŒ„é–‹å§‹æ™‚é–“
            import time
            start_time = time.time()
            last_progress_time = start_time
            
            filtered_rows = []
            
            for row in range(scan_start, scan_end + 1):
                try:
                    # å„ªåŒ–ç­–ç•¥ï¼šå¾Column Hé–‹å§‹åˆ¤æ–·ï¼Œå› ç‚ºHæ˜¯æœ€ç´°åˆ†çš„ç¬¬ä¸‰ç´šç›®éŒ„
                    # å¦‚æœHä¸åŒ¹é…ï¼Œå¾ˆå¯èƒ½Få’ŒGä¹Ÿä¸åŒ¹é…ï¼Œå¯ä»¥è·³éå¾ŒçºŒæª¢æŸ¥
                    matches = True
                    
                    # 1. é¦–å…ˆæª¢æŸ¥ç¬¬Håˆ—ï¼ˆç¬¬8åˆ—ï¼‰- ç¬¬ä¸‰ç´šç›®éŒ„
                    if 'column_h_value' in conditions:
                        cell_value = worksheet.cell(row=row, column=8).value
                        if cell_value is None:
                            cell_value = ""
                        if str(cell_value).strip() != conditions['column_h_value']:
                            matches = False
                            # Håˆ—ä¸åŒ¹é…ï¼Œè·³éå¾ŒçºŒæª¢æŸ¥
                            continue
                        else:
                            logger.debug(f"ç¬¬{row}è¡ŒHåˆ—åŒ¹é…: {cell_value}")
                    
                    # 2. å¦‚æœHåˆ—åŒ¹é…ï¼Œæª¢æŸ¥ç¬¬Gåˆ—ï¼ˆç¬¬7åˆ—ï¼‰- ç¬¬äºŒç´šç›®éŒ„
                    if matches and 'column_g_value' in conditions:
                        cell_value = worksheet.cell(row=row, column=7).value
                        if cell_value is None:
                            cell_value = ""
                        if str(cell_value).strip() != conditions['column_g_value']:
                            matches = False
                            # Gåˆ—ä¸åŒ¹é…ï¼Œè·³éFåˆ—æª¢æŸ¥
                            continue
                        else:
                            logger.debug(f"ç¬¬{row}è¡ŒGåˆ—åŒ¹é…: {cell_value}")
                    
                    # 3. å¦‚æœGåˆ—ä¹ŸåŒ¹é…ï¼Œæª¢æŸ¥ç¬¬Fåˆ—ï¼ˆç¬¬6åˆ—ï¼‰- ç¬¬ä¸€ç´šç›®éŒ„
                    if matches and 'column_f_value' in conditions:
                        cell_value = worksheet.cell(row=row, column=6).value
                        if cell_value is None:
                            cell_value = ""
                        if str(cell_value).strip() != conditions['column_f_value']:
                            matches = False
                            # Fåˆ—ä¸åŒ¹é…ï¼Œè©²è¡Œä¸ç¬¦åˆæ¢ä»¶
                            continue
                        else:
                            logger.debug(f"ç¬¬{row}è¡ŒFåˆ—åŒ¹é…: {cell_value}")
                    
                    # æ‰€æœ‰è¨­ç½®çš„åˆ—å€¼æ¢ä»¶éƒ½åŒ¹é…
                    if matches:
                        filtered_rows.append(row)
                        logger.debug(f"ç¬¬{row}è¡Œé€šéæ‰€æœ‰åˆ—å€¼éæ¿¾")
                        
                        # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™æ•¸é‡ï¼ˆåƒ…ç”¨æ–¼æ—¥èªŒï¼Œä¸åœæ­¢æƒæï¼‰
                        if len(filtered_rows) >= required_count and not score_all_filtered:
                            logger.info(f"å·²æ‰¾åˆ°è¶³å¤ çš„éæ¿¾çµæœ: {len(filtered_rows)}æ¢ï¼Œç›®æ¨™: {required_count}æ¢ï¼Œç¹¼çºŒæƒæä»¥å»ºç«‹å®Œæ•´ç·©å­˜")
                    
                    # é€²åº¦æ›´æ–°ï¼šæ ¹æ“šæ–‡ä»¶å¤§å°å‹•æ…‹èª¿æ•´æ›´æ–°é »ç‡
                    if scan_end - scan_start > 1000:
                        # å¤§æ–‡ä»¶ï¼šæ¯500è¡Œæ›´æ–°ä¸€æ¬¡
                        progress_step = 500
                    elif scan_end - scan_start > 500:
                        # ä¸­ç­‰æ–‡ä»¶ï¼šæ¯200è¡Œæ›´æ–°ä¸€æ¬¡
                        progress_step = 200
                    else:
                        # å°æ–‡ä»¶ï¼šæ¯100è¡Œæ›´æ–°ä¸€æ¬¡
                        progress_step = 100
                    
                    if row % progress_step == 0:
                        current_time = time.time()
                        elapsed_time = current_time - start_time
                        rows_per_second = row / elapsed_time if elapsed_time > 0 else 0
                        target_info = "å…¨éƒ¨" if required_count == float('inf') else f"ç›®æ¨™ {required_count} è¡Œï¼ˆå®Œæ•´æƒæå»ºç«‹ç·©å­˜ï¼‰"
                        logger.info(f"å¿«é€Ÿéæ¿¾é€²åº¦: å·²æƒæåˆ°ç¬¬ {row} è¡Œï¼Œç•¶å‰æ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…ï¼Œ{target_info}ï¼Œè€—æ™‚ {elapsed_time:.1f}ç§’ï¼Œé€Ÿåº¦ {rows_per_second:.1f}è¡Œ/ç§’")
                        last_progress_time = current_time
                    
                    # æ¯100è¡Œä¹Ÿæ›´æ–°ä¸€æ¬¡ï¼ˆä½œç‚ºä¸»è¦é€²åº¦é»ï¼Œé©ç”¨æ–¼æ‰€æœ‰æ–‡ä»¶å¤§å°ï¼‰
                    if row % 100 == 0:
                        current_time = time.time()
                        elapsed_time = current_time - start_time
                        rows_per_second = row / elapsed_time if elapsed_time > 0 else 0
                        target_info = "å…¨éƒ¨" if required_count == float('inf') else f"ç›®æ¨™ {required_count} è¡Œï¼ˆå®Œæ•´æƒæå»ºç«‹ç·©å­˜ï¼‰"
                        logger.info(f"å¿«é€Ÿéæ¿¾ä¸»è¦é€²åº¦: å·²æƒæåˆ°ç¬¬ {row} è¡Œï¼Œç•¶å‰æ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…ï¼Œ{target_info}ï¼Œè€—æ™‚ {elapsed_time:.1f}ç§’ï¼Œé€Ÿåº¦ {rows_per_second:.1f}è¡Œ/ç§’")
                    
                    # æ¯500è¡Œæ›´æ–°ä¸€æ¬¡ï¼ˆä½œç‚ºå¤§é€²åº¦é»ï¼Œé©ç”¨æ–¼å¤§æ–‡ä»¶ï¼‰
                    if row % 500 == 0:
                        current_time = time.time()
                        elapsed_time = current_time - start_time
                        rows_per_second = row / elapsed_time if elapsed_time > 0 else 0
                        target_info = "å…¨éƒ¨" if required_count == float('inf') else f"ç›®æ¨™ {required_count} è¡Œï¼ˆå®Œæ•´æƒæå»ºç«‹ç·©å­˜ï¼‰"
                        logger.info(f"å¿«é€Ÿéæ¿¾å¤§é€²åº¦: å·²æƒæåˆ°ç¬¬ {row} è¡Œï¼Œç•¶å‰æ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…ï¼Œ{target_info}ï¼Œè€—æ™‚ {elapsed_time:.1f}ç§’ï¼Œé€Ÿåº¦ {rows_per_second:.1f}è¡Œ/ç§’")
                    
                    # å¦‚æœè¶…é5ç§’æ²’æœ‰é€²åº¦æ›´æ–°ï¼Œå¼·åˆ¶è¼¸å‡ºä¸€æ¬¡
                    current_time = time.time()
                    if current_time - last_progress_time > 5:
                        target_info = "å…¨éƒ¨" if required_count == float('inf') else f"ç›®æ¨™ {required_count} è¡Œï¼ˆå®Œæ•´æƒæå»ºç«‹ç·©å­˜ï¼‰"
                        logger.info(f"å¼·åˆ¶é€²åº¦æ›´æ–°: å·²æƒæåˆ°ç¬¬ {row} è¡Œï¼Œç•¶å‰æ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…ï¼Œ{target_info}ï¼Œè€—æ™‚ {current_time - start_time:.1f}ç§’")
                        last_progress_time = current_time
                
                except Exception as e:
                    logger.warning(f"å¿«é€Ÿéæ¿¾ç¬¬ {row} è¡Œæ™‚å‡ºéŒ¯: {e}")
                    continue
            
            # æƒæå®Œæˆå¾Œçš„ç¸½çµæ—¥èªŒ
            total_scanned = row - scan_start + 1 if 'row' in locals() else 0
            if score_all_filtered:
                logger.info(f"å¿«é€Ÿåˆ—å€¼éæ¿¾å®Œæˆï¼Œå…¨éƒ¨è©•åˆ†æ¨¡å¼ï¼Œæ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…")
                logger.info(f"æƒæçµ±è¨ˆ: å¾ç¬¬{scan_start}è¡Œåˆ°ç¬¬{scan_end}è¡Œï¼Œå…±æƒæ{scan_end - scan_start + 1}è¡Œ")
            elif len(filtered_rows) >= required_count:
                logger.info(f"å¿«é€Ÿåˆ—å€¼éæ¿¾å®Œæˆï¼Œå·²æ‰¾åˆ°è¶³å¤ çš„çµæœ: {len(filtered_rows)}æ¢ï¼Œç›®æ¨™: {required_count}æ¢")
                logger.info(f"æƒæçµ±è¨ˆ: å¾ç¬¬{scan_start}è¡Œåˆ°ç¬¬{scan_end}è¡Œï¼Œå…±æƒæ{scan_end - scan_start + 1}è¡Œï¼ˆå®Œæ•´æƒæä»¥å»ºç«‹ç·©å­˜ï¼‰")
            else:
                logger.info(f"å¿«é€Ÿåˆ—å€¼éæ¿¾å®Œæˆï¼Œæ‰¾åˆ° {len(filtered_rows)} è¡ŒåŒ¹é…ï¼Œç›®æ¨™: {required_count}è¡Œ")
                logger.info(f"æƒæçµ±è¨ˆ: å¾ç¬¬{scan_start}è¡Œåˆ°ç¬¬{scan_end}è¡Œï¼Œå…±æƒæ{scan_end - scan_start + 1}è¡Œ")
            
            # è¨ˆç®—éæ¿¾æ•ˆç‡çµ±è¨ˆ
            if score_all_filtered:
                # å…¨éƒ¨è©•åˆ†æ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´æƒæç¯„åœ
                total_scanned = scan_end - scan_start + 1
            efficiency = (len(filtered_rows) / total_scanned) * 100 if total_scanned > 0 else 0
            logger.info(f"éæ¿¾æ•ˆç‡: {efficiency:.2f}% ({len(filtered_rows)}/{total_scanned})")
            
            # ä¿å­˜ç·©å­˜çµæœ
            if self.filter_cache and filtered_rows:
                excel_file = self.config.get('excel', 'file_path')
                f_value = conditions.get('column_f_value', '')
                g_value = conditions.get('column_g_value', '')
                h_value = conditions.get('column_h_value', '')
                
                # æº–å‚™æƒæçµ±è¨ˆä¿¡æ¯
                scan_stats = {
                    'scan_start': scan_start,
                    'scan_end': row if 'row' in locals() else scan_end,
                    'total_scanned': total_scanned,
                    'efficiency': efficiency,
                    'scan_time': time.time() - start_time if 'start_time' in locals() else 0
                }
                
                self.filter_cache.save_filter_result(excel_file, f_value, g_value, h_value, filtered_rows, scan_stats)
                logger.info(f"ç·©å­˜å·²ä¿å­˜ï¼Œå…± {len(filtered_rows)} è¡Œçµæœ")
            
            return filtered_rows
            
        except Exception as e:
            logger.error(f"å¿«é€Ÿåˆ—å€¼éæ¿¾å¤±æ•—: {e}")
            return []

    def _traditional_scan_filter(self, worksheet) -> List[int]:
        """å‚³çµ±æƒæéæ¿¾æ¨¡å¼"""
        try:
            logger.info("é–‹å§‹å‚³çµ±æƒæéæ¿¾...")
            
            # ç²å–æ‰€æœ‰è¡Œ
            logger.info("é–‹å§‹æƒæExcelè¡Œ...")
            all_rows = []
            
            # å„ªåŒ–ï¼šåªæƒææœ‰æ•¸æ“šçš„è¡Œï¼Œè·³éç©ºè¡Œ
            max_row = worksheet.max_row
            logger.info(f"Excelç¸½è¡Œæ•¸: {max_row}")
            
            # å¾ç¬¬7è¡Œé–‹å§‹æƒæï¼ˆè·³éæ¨™é¡Œè¡Œå’Œèªªæ˜è¡Œï¼‰
            scan_start = 7
            
            # æ ¹æ“šé…ç½®æ±ºå®šæƒæç¯„åœ
            scan_full_file = self.config.getboolean('filter', 'scan_full_file', fallback=True)
            if scan_full_file:
                scan_end = max_row  # æƒæå®Œæ•´æ–‡ä»¶ä»¥å»ºç«‹å®Œæ•´ç·©å­˜
                logger.info("ğŸ” æƒæç­–ç•¥: å®Œæ•´æ–‡ä»¶æƒæï¼ˆå»ºç«‹å®Œæ•´ç·©å­˜ï¼‰")
            else:
                scan_end = min(max_row, 1000)  # é™åˆ¶æƒæç¯„åœä»¥æ§åˆ¶æ€§èƒ½
                logger.info("âš ï¸ æƒæç­–ç•¥: é™åˆ¶æƒæç¯„åœï¼ˆç·©å­˜ä¸å®Œæ•´ï¼Œä¸æ¨è–¦ï¼‰")
            
            logger.info(f"æƒæç¯„åœ: ç¬¬{scan_start}è¡Œåˆ°ç¬¬{scan_end}è¡Œ")
            
            for row in range(scan_start, scan_end + 1):
                try:
                    # å¿«é€Ÿæª¢æŸ¥æ˜¯å¦æœ‰å…§å®¹ï¼ˆåªæª¢æŸ¥å•é¡Œåˆ—ï¼‰
                    question_col = self.config.getint('excel', 'question_column')
                    cell_value = worksheet.cell(row=row, column=question_col).value
                    
                    if cell_value and str(cell_value).strip():
                        all_rows.append(row)
                        
                        # æ¯100è¡Œè¨˜éŒ„ä¸€æ¬¡é€²åº¦
                        if len(all_rows) % 100 == 0:
                            logger.info(f"å·²æ‰¾åˆ° {len(all_rows)} è¡Œæœ‰å…§å®¹çš„æ•¸æ“šï¼Œç•¶å‰æƒæåˆ°ç¬¬ {row} è¡Œ")
                    
                except Exception as e:
                    logger.warning(f"æƒæç¬¬ {row} è¡Œæ™‚å‡ºéŒ¯: {e}")
                    continue
            
            logger.info(f"æƒæå®Œæˆï¼Œæ‰¾åˆ° {len(all_rows)} è¡Œæœ‰å…§å®¹çš„æ•¸æ“š")
            return all_rows
            
        except Exception as e:
            logger.error(f"å‚³çµ±æƒæéæ¿¾å¤±æ•—: {e}")
            return []

    def process_batch(self, start_row: int = None, end_row: int = None, results_file: str = None):
        """æ‰¹é‡è™•ç†å•ç­”ç²¾é¸è©•åˆ†ï¼Œè¼¸å‡ºåˆ°JSONæ–‡ä»¶"""
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        overall_start_time = time.time()
        logger.info(f"ğŸš€ é–‹å§‹æ‰¹é‡è™•ç† - æ™‚é–“: {datetime.now().strftime('%H:%M:%S')}")
        
        # è¼‰å…¥é…ç½®
        if start_row is None:
            start_row = self.config.getint('processing', 'start_row', fallback=2)
        if end_row is None:
            config_end_row = self.config.getint('processing', 'end_row', fallback=0)
            end_row = config_end_row if config_end_row > 0 else None
        
        if results_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = f'qa_curation_results_{timestamp}.json'
        
        logger.info(f"ğŸ“ çµæœæ–‡ä»¶: {results_file}")
        
        # è¼‰å…¥å·²æœ‰çµæœï¼ˆæ”¯æŒçºŒè™•ç†ï¼‰
        logger.info("ğŸ“‚ è¼‰å…¥å·²æœ‰çµæœ...")
        load_start = time.time()
        self.curation_results = self.load_existing_results(results_file)
        load_time = time.time() - load_start
        logger.info(f"âœ… å·²æœ‰çµæœè¼‰å…¥å®Œæˆï¼Œè€—æ™‚: {load_time:.2f}ç§’")
        
        # è¼‰å…¥Excel
        logger.info("ğŸ“Š è¼‰å…¥Excelæ•¸æ“š...")
        excel_start = time.time()
        workbook, worksheet = self.load_excel_data()
        excel_time = time.time() - excel_start
        logger.info(f"âœ… Excelæ•¸æ“šè¼‰å…¥å®Œæˆï¼Œè€—æ™‚: {excel_time:.2f}ç§’")
        
        # æª¢æŸ¥è™•ç†æ¨¡å¼
        use_filter_mode = self.config.getboolean('processing', 'use_filter_mode', fallback=False)
        
        if use_filter_mode:
            # éæ¿¾æ¨¡å¼
            logger.info("ğŸ” ä½¿ç”¨éæ¿¾æ¨¡å¼...")
            self.processing_metadata['processing_mode'] = "filter_mode"
            
            filter_start = time.time()
            rows_to_process = self.get_filtered_rows(worksheet)
            filter_time = time.time() - filter_start
            
            if not rows_to_process:
                logger.warning("âš ï¸ éæ¿¾æ¨¡å¼ä¸‹æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è¡Œ")
                return results_file
            
            logger.info(f"âœ… éæ¿¾å®Œæˆï¼Œæ‰¾åˆ° {len(rows_to_process)} è¡Œï¼Œè€—æ™‚: {filter_time:.2f}ç§’")
            
            # ç²å–éæ¿¾çµæœçš„è©•åˆ†ç¯„åœ
            filter_start_index = self.config.getint('filter', 'start_index', fallback=0)
            filter_end_index = self.config.getint('filter', 'end_index', fallback=0)
            
            if filter_end_index > 0:
                # æŒ‡å®šç¯„åœ
                start_idx = max(0, filter_start_index)
                end_idx = min(len(rows_to_process), filter_end_index + 1)
                rows_to_process = rows_to_process[start_idx:end_idx]
                logger.info(f"ğŸ¯ éæ¿¾æ¨¡å¼ï¼šè™•ç†ç¬¬ {start_idx+1} åˆ°ç¬¬ {end_idx} æ¢éæ¿¾çµæœï¼Œå…± {len(rows_to_process)} æ¢")
            else:
                # åªè™•ç†ç¬¬ä¸€æ¢
                rows_to_process = rows_to_process[:1]
                logger.info("ğŸ¯ éæ¿¾æ¨¡å¼ï¼šåªè™•ç†ç¬¬ä¸€æ¢éæ¿¾çµæœ")
            
        else:
            # å‚³çµ±æ¨¡å¼ï¼ˆæŒ‡å®šè¡Œè™Ÿï¼‰
            logger.info("ğŸ“ ä½¿ç”¨è¡Œè™Ÿæ¨¡å¼...")
            self.processing_metadata['processing_mode'] = "row_mode"
            
            # ç¢ºå®šè™•ç†ç¯„åœ
            max_row = worksheet.max_row
            if end_row is None or end_row > max_row:
                end_row = max_row
            
            rows_to_process = list(range(start_row, end_row + 1))
            logger.info(f"ğŸ¯ è¡Œè™Ÿæ¨¡å¼ï¼šè™•ç†ç¬¬ {start_row} åˆ° {end_row} è¡Œï¼Œå…± {len(rows_to_process)} æ¢è¨˜éŒ„")
        
        # é–‹å§‹è©•åˆ†è™•ç†
        total_count = len(rows_to_process)
        logger.info(f"ğŸš€ é–‹å§‹è©•åˆ†è™•ç†ï¼Œç¸½ç›®æ¨™: {total_count} æ¢è¨˜éŒ„")
        
        # é¡¯ç¤ºé€²åº¦æ¢
        self._display_progress_bar(0, total_count, "é–‹å§‹è™•ç†")
        
        processed_count = 0
        success_count = 0
        failed_count = 0
        skipped_count = 0
        
        # è¨˜éŒ„è™•ç†é–‹å§‹æ™‚é–“
        processing_start_time = time.time()
        last_save_time = processing_start_time
        
        for i, row in enumerate(rows_to_process):
            current_time = time.time()
            elapsed_time = current_time - processing_start_time
            
            # è¨ˆç®—é€²åº¦å’Œé ä¼°æ™‚é–“
            progress_percent = (i / total_count) * 100 if total_count > 0 else 0
            if i > 0:
                avg_time_per_item = elapsed_time / i
                remaining_items = total_count - i
                estimated_remaining_time = remaining_items * avg_time_per_item
                
                logger.info(f"ğŸ“ˆ é€²åº¦: {i+1}/{total_count} ({progress_percent:.1f}%) - å·²è€—æ™‚: {elapsed_time:.1f}ç§’")
                logger.info(f"â³ é ä¼°å‰©é¤˜æ™‚é–“: {estimated_remaining_time:.1f}ç§’ ({estimated_remaining_time/60:.1f}åˆ†é˜)")
                logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {i/elapsed_time:.2f} æ¢/ç§’")
            
            # æ›´æ–°é€²åº¦æ¢
            self._display_progress_bar(i + 1, total_count, f"è™•ç†ç¬¬{i+1}æ¢")
            
            try:
                # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
                row_key = str(row)
                if row_key in self.curation_results:
                    logger.info(f"â­ï¸ ç¬¬ {row} è¡Œå·²è™•ç†ï¼Œè·³é")
                    skipped_count += 1
                    continue
                
                # æå–å•ç­”å…§å®¹
                logger.info(f"ğŸ“– æå–ç¬¬ {row} è¡Œå•ç­”å…§å®¹...")
                extract_start = time.time()
                question, answer = self.extract_qa_content(worksheet, row)
                extract_time = time.time() - extract_start
                
                if not question and not answer:
                    logger.info(f"âš ï¸ ç¬¬ {row} è¡Œç„¡å…§å®¹ï¼Œè·³é")
                    skipped_count += 1
                    continue
                
                logger.info(f"ğŸ”„ è™•ç†ç¬¬ {row} è¡Œ: {question[:100]}...")
                logger.info(f"ğŸ“Š å…§å®¹æå–è€—æ™‚: {extract_time:.2f}ç§’")
                
                # é€²è¡Œç²¾é¸è©•åˆ†
                logger.info(f"ğŸ¤– é–‹å§‹AIè©•åˆ†...")
                scoring_start = time.time()
                result = self.evaluate_qa_quality(question, answer)
                scoring_time = time.time() - scoring_start
                logger.info(f"âœ… AIè©•åˆ†å®Œæˆï¼Œè€—æ™‚: {scoring_time:.2f}ç§’")
                
                # ä¿å­˜çµæœ
                logger.info(f"ğŸ’¾ ä¿å­˜è©•åˆ†çµæœ...")
                save_start = time.time()
                self.curation_results[row_key] = {
                    'row_number': row,
                    'question': question[:500],  # é™åˆ¶é•·åº¦
                    'answer': answer[:1000],     # é™åˆ¶é•·åº¦
                    'breadth_score': result.get('breadth_score', ''),
                    'depth_score': result.get('depth_score', ''),
                    'uniqueness_score': result.get('uniqueness_score', ''),
                    'overall_score': result.get('overall_score', ''),
                    'breadth_comment': result.get('breadth_comment', ''),
                    'depth_comment': result.get('depth_comment', ''),
                    'uniqueness_comment': result.get('uniqueness_comment', ''),
                    'overall_comment': result.get('overall_comment', ''),
                    'question_summary': result.get('question_summary', ''),
                    'answer_summary': result.get('answer_summary', ''),
                    'status': result.get('status', 'success'),  # ä½¿ç”¨getæ–¹æ³•ï¼Œé»˜èªç‚ºsuccess
                    'processed_time': datetime.now().isoformat()
                }
                save_time = time.time() - save_start
                logger.info(f"âœ… çµæœä¿å­˜å®Œæˆï¼Œè€—æ™‚: {save_time:.2f}ç§’")
                
                processed_count += 1
                if result.get('status') == 'success':
                    success_count += 1
                
                # è¨ˆç®—ç¸½è€—æ™‚
                total_item_time = extract_time + scoring_time + save_time
                logger.info(f"âœ… ç¬¬ {row} è¡Œè™•ç†å®Œæˆï¼Œç¸½è€—æ™‚: {total_item_time:.2f}ç§’")
                
                # æ¯è™•ç†10æ¢è¨˜éŒ„ä¿å­˜ä¸€æ¬¡
                if processed_count % 10 == 0:
                    logger.info(f"ğŸ’¾ åŸ·è¡Œä¸­é–“ä¿å­˜...")
                    save_start = time.time()
                    self.save_results(results_file)
                    save_time = time.time() - save_start
                    last_save_time = time.time()
                    logger.info(f"âœ… ä¸­é–“ä¿å­˜å®Œæˆï¼Œå·²è™•ç† {processed_count} æ¢è¨˜éŒ„ï¼Œä¿å­˜è€—æ™‚: {save_time:.2f}ç§’")
                
                # APIèª¿ç”¨é–“éš”
                if i < total_count - 1:  # ä¸æ˜¯æœ€å¾Œä¸€æ¢
                    logger.info(f"â¸ï¸ ç­‰å¾…1ç§’å¾Œè™•ç†ä¸‹ä¸€æ¢...")
                    time.sleep(1)
                
            except Exception as e:
                logger.error(f"âŒ è™•ç†ç¬¬ {row} è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                failed_count += 1
                processed_count += 1
                continue
        
        # æœ€çµ‚ä¿å­˜
        logger.info(f"ğŸ’¾ åŸ·è¡Œæœ€çµ‚ä¿å­˜...")
        final_save_start = time.time()
        self.save_results(results_file)
        final_save_time = time.time() - final_save_start
        
        # è¨ˆç®—ç¸½çµ±è¨ˆ
        total_time = time.time() - overall_start_time
        processing_time = time.time() - processing_start_time
        
        logger.info(f"ğŸ‰ æ‰¹é‡è™•ç†å®Œæˆï¼")
        logger.info(f"ğŸ“Š çµ±è¨ˆçµæœ:")
        logger.info(f"   - ç¸½è¨ˆ: {total_count} æ¢")
        logger.info(f"   - æˆåŠŸ: {success_count} æ¢")
        logger.info(f"   - å¤±æ•—: {failed_count} æ¢")
        logger.info(f"   - è·³é: {skipped_count} æ¢")
        logger.info(f"â±ï¸ æ™‚é–“çµ±è¨ˆ:")
        logger.info(f"   - ç¸½è€—æ™‚: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†é˜)")
        logger.info(f"   - è™•ç†è€—æ™‚: {processing_time:.2f}ç§’ ({processing_time/60:.1f}åˆ†é˜)")
        logger.info(f"   - æœ€çµ‚ä¿å­˜è€—æ™‚: {final_save_time:.2f}ç§’")
        if processed_count > 0:
            logger.info(f"ğŸš€ æ€§èƒ½çµ±è¨ˆ:")
            logger.info(f"   - å¹³å‡é€Ÿåº¦: {processed_count/processing_time:.2f} æ¢/ç§’")
            logger.info(f"   - å¹³å‡æ¯æ¢è€—æ™‚: {processing_time/processed_count:.2f} ç§’")
        
        return results_file

    def _display_progress_bar(self, current: int, total: int, status: str = ""):
        """é¡¯ç¤ºé€²åº¦æ¢"""
        try:
            if total <= 0:
                return
            
            # è¨ˆç®—é€²åº¦ç™¾åˆ†æ¯”
            progress = (current / total) * 100
            
            # é€²åº¦æ¢é•·åº¦
            bar_length = 30
            filled_length = int(bar_length * current // total)
            
            # æ§‹å»ºé€²åº¦æ¢
            bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
            
            # é¡¯ç¤ºé€²åº¦æ¢
            print(f"\rğŸ“Š é€²åº¦: [{bar}] {current}/{total} ({progress:.1f}%) - {status}", end='', flush=True)
            
            # å¦‚æœå®Œæˆï¼Œæ›è¡Œ
            if current >= total:
                print()
                
        except Exception as e:
            logger.warning(f"é€²åº¦æ¢é¡¯ç¤ºå¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="ä½›å­¸å•ç­”ç²¾é¸è‡ªå‹•åŒ–ç³»çµ±",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨OpenAI APIï¼ˆæ¨è–¦ï¼‰
  python3 qa_curator.py --api-key YOUR_API_KEY --api-type openai
  
  # ä½¿ç”¨ChatMock
  python3 qa_curator.py --api-type chatmock
  
  # ä½¿ç”¨ç’°å¢ƒè®Šé‡
  export OPENAI_API_KEY=YOUR_API_KEY
  python3 qa_curator.py --api-type openai
  
  # ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆä¸æ¨è–¦ï¼Œæœƒç”¢ç”Ÿcommitè­¦å‘Šï¼‰
  python3 qa_curator.py
        """
    )
    
    parser.add_argument(
        '--api-key',
        type=str,
        help='OpenAI API Keyï¼ˆæ¨è–¦ä½¿ç”¨æ­¤æ–¹å¼ï¼‰'
    )
    
    parser.add_argument(
        '--api-type',
        type=str,
        choices=['openai', 'chatmock'],
        help='APIé¡å‹é¸æ“‡ï¼šopenai æˆ– chatmockï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶è¨­ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--chatmock-url',
        type=str,
        help='ChatMockæœå‹™å™¨åœ°å€ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶è¨­ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config.ini',
        help='é…ç½®æ–‡ä»¶è·¯å¾‘ï¼ˆé»˜èª: config.iniï¼‰'
    )
    
    args = parser.parse_args()
    
    print("ä½›å­¸å•ç­”ç²¾é¸è‡ªå‹•åŒ–ç³»çµ±")
    print("=" * 50)
    
    try:
        curator = BuddhistQACurator(
            config_file=args.config,
            api_key=args.api_key,
            api_type=args.api_type,
            chatmock_url=args.chatmock_url
        )
        
        # è™•ç†æŒ‡å®šç¯„åœ
        results_file = curator.process_batch()
        
        print(f"\nâœ… ç²¾é¸è©•åˆ†å®Œæˆï¼çµæœå·²ä¿å­˜åˆ°: {results_file}")
        print("æ¥ä¸‹ä¾†è«‹é‹è¡Œ results_to_excel.py å°‡çµæœå¯«å…¥Excelæ–‡ä»¶")
        
    except Exception as e:
        logger.error(f"ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
        print(f"âŒ ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")

if __name__ == "__main__":
    main()
